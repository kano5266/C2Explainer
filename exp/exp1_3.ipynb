{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75750720-6a58-449b-8b50-ef4b89b5aaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
      "PyTorch version: 2.0.1\n",
      "PyTorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU\n",
    "import torch_geometric\n",
    "from torch_geometric.explain import Explainer\n",
    "from torch_geometric.nn import SAGEConv, GATConv, GINConv, GIN, GCNConv\n",
    "from cf_explainer import C2Explainer\n",
    "from torch_geometric.nn import global_mean_pool,  global_max_pool\n",
    "from cf_explainer.utils import seed_everything\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# import networkx as nx\n",
    "# from pyvis.network import Network\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "'''Config parameters'''\n",
    "use_cuda_if_available = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and use_cuda_if_available else 'cpu')\n",
    "\n",
    "# seed_everything(42, deterministic=True)\n",
    "# if error when setting use_deterministic_algorithms(True)\n",
    "# try this:\n",
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"PyTorch device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e638ff49-64f2-4968-9206-7b1bf8183505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def results(num_perturbs, prop_perturbs):\n",
    "    print(\"######\")\n",
    "    if len(num_perturbs) != 0:\n",
    "        size = sum(num_perturbs)/(2*len(num_perturbs))\n",
    "        prop = sum(prop_perturbs)/len(prop_perturbs)\n",
    "    else:\n",
    "        size = \"N/A\"\n",
    "        prop = \"N/A\"\n",
    "    print(f\"size: {size}, num_success: {len(num_perturbs)}, prop_perturbs: {prop}\")\n",
    "    print(\"finished\")\n",
    "    return size, prop\n",
    "\n",
    "\n",
    "def explain(model, dataset, explainer, seed=42):\n",
    "    seed_everything(seed, deterministic=True)\n",
    "    result = []\n",
    "    \n",
    "    explainer = Explainer(\n",
    "        model=model,\n",
    "        algorithm=explainer,\n",
    "        explanation_type='model',\n",
    "        node_mask_type=None,\n",
    "        edge_mask_type='object',\n",
    "        model_config=dict(\n",
    "            mode='multiclass_classification',\n",
    "            task_level='graph',\n",
    "            return_type='raw',\n",
    "        ), \n",
    "    )\n",
    "    \n",
    "    # cfs = []\n",
    "    num_perturbs = []\n",
    "    prop_perturbs = []\n",
    "\n",
    "    for data in tqdm(test_dataset):\n",
    "        explanation = explainer(data.x, data.edge_index, batch=None)\n",
    "        \n",
    "        if hasattr(explanation, \"perturbs\"):\n",
    "            if explanation.perturbs < 20:\n",
    "                # cfs.append(explanation.cf)\n",
    "                num_perturbs.append(explanation.perturbs)\n",
    "                prop_perturbs.append(explanation.prop_perturbs)\n",
    "    \n",
    "    size, prop = results(num_perturbs, prop_perturbs)\n",
    "    \n",
    "    result.append([len(test_dataset), size, len(num_perturbs), prop])\n",
    "    print(f\"Fedility: {len(num_perturbs)/len(test_dataset)}, Num_perturbs: {size}, Similarity: {1-prop}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578d461-b251-4b59-ab22-c4721adfbb9a",
   "metadata": {},
   "source": [
    "# BA2Motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e496bf9-c1be-46af-b540-e492a900f966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ymmt4090no1/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, nhid, nout, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(10, nhid, normalize=False)\n",
    "        self.conv2 = GCNConv(nhid, nhid, normalize=False)\n",
    "        self.conv3 = GCNConv(nhid, nout, normalize=False)\n",
    "        self.lin = Linear(nout, 2)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, batch, edge_weight=None):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_max_pool(x, batch)  # [batch_size, nhid]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(nhid=20, nout=20, dropout=0).to(device)\n",
    "model.load_state_dict(torch.load(\"../models/GCN_BA2Motifs_sd.pt\", weights_only=True))\n",
    "\n",
    "with open(\"../data/BA2motifs.pickle\", \"rb\") as f:\n",
    "\tdataset = pickle.load(f)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:0.8]\n",
    "test_dataset = dataset[0.8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd47058-17a5-4d06-9a72-2cf7166ec334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59649e53fc61472c8fe5ee0aa281beb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      "size: 1.803191489361702, num_success: 188, prop_perturbs: 0.07015821058374232\n",
      "finished\n",
      "Fedility: 0.94, Num_perturbs: 1.803191489361702, Similarity: 0.9298417894162577\n",
      "CPU times: user 8min 31s, sys: 1.11 s, total: 8min 32s\n",
      "Wall time: 8min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "explainer = C2Explainer(epochs=1000, lr=0.1, subgraph_mode=True, silent_mode=True, undirected=True)\n",
    "\n",
    "result1 = explain(model, test_dataset, explainer, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06340e6a-3e21-4aa9-9577-4424052b19ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492cc41cf3af48a68c41332ba6950b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      "size: 1.7842105263157895, num_success: 190, prop_perturbs: 0.06954183535762462\n",
      "finished\n",
      "Fedility: 0.95, Num_perturbs: 1.7842105263157895, Similarity: 0.9304581646423754\n",
      "CPU times: user 8min 55s, sys: 1.21 s, total: 8min 57s\n",
      "Wall time: 9min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "explainer = C2Explainer(epochs=1000, lr=0.1, silent_mode=True, undirected=True)\n",
    "\n",
    "result1 = explain(model, test_dataset, explainer, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4febba48-ac2b-4e43-bbcc-a5f3b31d4163",
   "metadata": {},
   "source": [
    "# MUTAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16ca0a62-3612-4273-82b9-84407a283dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, nhid, nout, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(7, nhid, normalize=False)\n",
    "        self.conv2 = GCNConv(nhid, nhid, normalize=False)\n",
    "        self.conv3 = GCNConv(nhid, nout, normalize=False)\n",
    "        self.lin = Linear(nout, 2)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, batch, edge_weight=None):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_max_pool(x, batch)  # [batch_size, nhid]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(nhid=20, nout=20, dropout=0).to(device)\n",
    "model.load_state_dict(torch.load(\"../models/GCN_MUTAG_sd.pt\", weights_only=True))\n",
    "\n",
    "with open(\"../data/MUTAG.pickle\", \"rb\") as f:\n",
    "\tdataset = pickle.load(f)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:0.8]\n",
    "test_dataset = dataset[0.8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "680362d2-3189-4a8c-a766-20fc7bc4ddf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a076913a15345948ef0365374b9da33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      "size: 2.121212121212121, num_success: 33, prop_perturbs: 0.12041421982233662\n",
      "finished\n",
      "Fedility: 0.868421052631579, Num_perturbs: 2.121212121212121, Similarity: 0.8795857801776634\n",
      "CPU times: user 1min 36s, sys: 188 ms, total: 1min 37s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "explainer = C2Explainer(epochs=1000, lr=0.1, subgraph_mode=True, silent_mode=True, undirected=True)\n",
    "\n",
    "result2 = explain(model, test_dataset, explainer, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e3a31c-1e1d-4a2e-bb88-af8f1d5f6ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56500e591544248b6b0706e01e1f185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######\n",
      "size: 1.6842105263157894, num_success: 38, prop_perturbs: 0.10486203322270968\n",
      "finished\n",
      "Fedility: 1.0, Num_perturbs: 1.6842105263157894, Similarity: 0.8951379667772903\n",
      "CPU times: user 1min 40s, sys: 245 ms, total: 1min 40s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "explainer = C2Explainer(epochs=1000, lr=0.1, silent_mode=True, undirected=True)\n",
    "\n",
    "result1 = explain(model, test_dataset, explainer, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c32ff0-fa40-416b-a62f-ceb8fd4454aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "pyg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
